import streamlit as st

#from langchain.text_splitter import CharacterTextSplitter
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.vectorstores import FAISS
from langchain.embeddings import OpenAIEmbeddings
from langchain.chat_models import ChatOpenAI
from langchain.schema import HumanMessage, SystemMessage
from langchain.callbacks.base import BaseCallbackHandler
from langchain.schema import ChatMessage

from dotenv import load_dotenv
from langchain.document_loaders import YoutubeLoader

load_dotenv()

# handle streaming conversation
class StreamHandler(BaseCallbackHandler):
    def __init__(self, container, initial_text=""):
        self.container = container
        self.text = initial_text

    def on_llm_new_token(self, token: str, **kwargs) -> None:
        self.text += token
        self.container.markdown(self.text)


# function to extract text from an HWP file
import olefile
import zlib
import struct

def get_hwp_text(filename):
    f = olefile.OleFileIO(filename)
    dirs = f.listdir()

    # HWP ÌååÏùº Í≤ÄÏ¶ù
    if ["FileHeader"] not in dirs or \
       ["\x05HwpSummaryInformation"] not in dirs:
        raise Exception("Not Valid HWP.")

    # Î¨∏ÏÑú Ìè¨Îß∑ ÏïïÏ∂ï Ïó¨Î∂Ä ÌôïÏù∏
    header = f.openstream("FileHeader")
    header_data = header.read()
    is_compressed = (header_data[36] & 1) == 1

    # Body Sections Î∂àÎü¨Ïò§Í∏∞
    nums = []
    for d in dirs:
        if d[0] == "BodyText":
            nums.append(int(d[1][len("Section"):]))
    sections = ["BodyText/Section"+str(x) for x in sorted(nums)]

    # Ï†ÑÏ≤¥ text Ï∂îÏ∂ú
    text = ""
    for section in sections:
        bodytext = f.openstream(section)
        data = bodytext.read()
        if is_compressed:
            unpacked_data = zlib.decompress(data, -15)
        else:
            unpacked_data = data
    
        # Í∞Å Section ÎÇ¥ text Ï∂îÏ∂ú    
        section_text = ""
        i = 0
        size = len(unpacked_data)
        while i < size:
            header = struct.unpack_from("<I", unpacked_data, i)[0]
            rec_type = header & 0x3ff
            rec_len = (header >> 20) & 0xfff

            if rec_type in [67]:
                rec_data = unpacked_data[i+4:i+4+rec_len]
                section_text += rec_data.decode('utf-16')
                section_text += "\n"

            i += 4 + rec_len

        text += section_text
        text += "\n"

    return text

# Function to extract text from an PDF file
from pdfminer.high_level import extract_text

def get_pdf_text(filename):
    raw_text = extract_text(filename)
    return raw_text

# document preprocess
#def process_uploaded_file(uploaded_file):
#    # Load document if file is uploadÎÖ∏Ìä∏
#    if uploaded_file is not None:
#        # loader
#        # pdfÌååÏùºÏùÑ Ï≤òÎ¶¨ÌïòÎ†§Î©¥?
#        if uploaded_file.type == 'application/pdf':
#            raw_text = get_pdf_text(uploaded_file)
#                    
#        # splitter
#        text_splitter = CharacterTextSplitter(
#            separator = "\n\n",
#            chunk_size = 1000,
#            chunk_overlap  = 200,
#            length_function = len,
#            is_separator_regex = False,
#        )
#        all_splits = text_splitter.create_documents([raw_text])
#        print("Ï¥ù " + str(len(all_splits)) + "Í∞úÏùò passage")
#        
#        # storage
#        vectorstore = FAISS.from_documents(documents=all_splits, embedding=OpenAIEmbeddings())
#                
#        return vectorstore, raw_text
#    return None

def process_uploaded_file(uploaded_files):
    vectorstores = {}
    raw_texts = {}
    try:
        for i, uploaded_file in enumerate(uploaded_files):
            if uploaded_file.type == 'application/pdf':
                raw_text = get_pdf_text(uploaded_file)
            else:
                st.error(f"Unsupported file type: {uploaded_file.type}")
                continue

            raw_text = raw_text.replace('\n\n', '\n').strip()

            text_splitter = RecursiveCharacterTextSplitter(
                chunk_size=500,
                chunk_overlap=50
            )
            all_splits = text_splitter.create_documents([raw_text])
            st.write(f"Lecture {i+1} Ï¥ù " + str(len(all_splits)) + "Í∞úÏùò passage")
            
            vectorstore = FAISS.from_documents(documents=all_splits, embedding=OpenAIEmbeddings())
            vectorstores[f'Lecture {i+1}'] = vectorstore
            raw_texts[f'Lecture {i+1}'] = raw_text

        return vectorstores, raw_texts
    except Exception as e:
        st.error(f"Error processing files: {e}")
        return None, None

def get_script(url, language="en", add_video_info=True):
    loader = YoutubeLoader.from_youtube_url(
        url,
        add_video_info=add_video_info,
        language=language,
    )
    return loader.load()

def load_youtube_scripts(urls):
    scripts = []
    for url in urls:
        try:
            script = get_script(url)
            for doc in script:
                scripts.append(doc.page_content)  # Ensure we extract the correct content
        except Exception as e:
            st.error(f"Error loading script for {url}: {e}")
    return scripts

# generate response using RAG technic
def generate_response(query_text, pdf_vectorstore, youtube_vectorstore, callback):
    pdf_docs = pdf_vectorstore.similarity_search(query_text, k=5)
    pdf_text = "".join([f"'Î¨∏ÏÑú{i+1}': {doc.page_content}\n" for i, doc in enumerate(pdf_docs)])
    
    youtube_docs = youtube_vectorstore.similarity_search(query_text, k=5)
    youtube_text = "".join([f"'ÎπÑÎîîÏò§{i+1}': {doc.page_content}\n" for i, doc in enumerate(youtube_docs)])

    examples = [
        {
            "role": "user",
            "content": "Í∞ïÏùòÎÖ∏Ìä∏ÏóêÏÑú 'Ï†ÑÍ∏∞ ÌöåÎ°ú'Ïóê ÎåÄÌïú ÏÑ§Î™ÖÏùÑ ÏïåÎ†§Ï§ò."
        },
        {
            "role": "assistant",
            "content": "Ï†ÑÍ∏∞ ÌöåÎ°úÎäî Ï†ÑÍ∏∞Í∞Ä ÌùêÎ•¥Îäî ÌÜµÎ°úÎ•º ÎßêÌï©ÎãàÎã§. Ï†ÑÍ∏∞ ÌöåÎ°úÎäî Î∞∞ÌÑ∞Î¶¨, Ï†ÑÏÑ†, Ï†ÄÌï≠, Ï†ÑÍµ¨ Îì±ÏúºÎ°ú Íµ¨ÏÑ±Îê©ÎãàÎã§. Ï†ÑÍ∏∞Í∞Ä ÌùêÎ•¥Í∏∞ ÏúÑÌï¥ÏÑúÎäî ÌöåÎ°úÍ∞Ä Îã´ÌòÄ ÏûàÏñ¥Ïïº Ìï©ÎãàÎã§. ÏòàÎ•º Îì§Ïñ¥, Î∞∞ÌÑ∞Î¶¨ÏóêÏÑú ÎÇòÏò® Ï†ÑÍ∏∞Í∞Ä Ï†ÑÏÑ†ÏùÑ ÌÜµÌï¥ Ï†ÄÌï≠Í≥º Ï†ÑÍµ¨Î•º Í±∞Ï≥ê Îã§Ïãú Î∞∞ÌÑ∞Î¶¨Î°ú ÎèåÏïÑÍ∞ÄÎäî Í≤ΩÎ°úÍ∞Ä ÏôÑÏÑ±Îê† Îïå Ï†ÑÍ∏∞ ÌöåÎ°úÍ∞Ä Îê©ÎãàÎã§. üîã‚û°Ô∏èüí°"
        },
        {
            "role": "user",
            "content": "Í∞ïÏùòÎÖ∏Ìä∏ÏóêÏÑú 'ÏßÑÎèô'Ïóê ÎåÄÌïú ÏÑ§Î™ÖÏùÑ ÏïåÎ†§Ï§ò."
        },
        {
            "role": "assistant",
            "content": "ÏßÑÎèôÏùÄ Î¨ºÏ≤¥Í∞Ä ÏùºÏ†ïÌïú Í∞ÑÍ≤©ÏúºÎ°ú Î∞òÎ≥µÌï¥ÏÑú ÏõÄÏßÅÏù¥Îäî ÌòÑÏÉÅÏùÑ ÎßêÌï©ÎãàÎã§. ÏòàÎ•º Îì§Ïñ¥, ÏãúÍ≥ÑÏùò Ï∂îÎÇò Í∏∞ÌÉÄ Ï§ÑÏùò ÏõÄÏßÅÏûÑÏù¥ ÏßÑÎèôÏùò ÏòàÏûÖÎãàÎã§. ÏßÑÎèôÏùò Ï£ºÍ∏∞ÏôÄ ÏßÑÌè≠ÏùÄ Í∞ÅÍ∞Å ÏßÑÎèôÏù¥ Ìïú Î≤à ÏôÑÎ£åÎêòÎäî Îç∞ Í±∏Î¶¨Îäî ÏãúÍ∞ÑÍ≥º ÏßÑÎèôÏùò ÏµúÎåÄ Î≥ÄÏúÑÏûÖÎãàÎã§. üé∏‚ÜîÔ∏èüé∂"
        }
    ]
    
    # generator
    llm = ChatOpenAI(model_name="gpt-4o", temperature=0.2, streaming=True, callbacks=[callback])
    
    # chaining
    rag_prompt = [
        SystemMessage(
            content="ÎÑàÎäî Í∞ïÏùòÎÖ∏Ìä∏ÏôÄ YouTube Í∞ïÏùò ÎßÅÌÅ¨Ïóê ÎåÄÌï¥ ÏßàÏùòÏùëÎãµÏùÑ ÌïòÎäî 'ÍµêÏàò'Ïïº. Ï£ºÏñ¥ÏßÑ Í∞ïÏùòÎÖ∏Ìä∏ÏôÄ YouTube Í∞ïÏùò ÎßÅÌÅ¨Î•º Ï∞∏Í≥†ÌïòÏó¨ ÏÇ¨Ïö©ÏûêÏùò ÏßàÎ¨∏Ïóê ÎãµÎ≥ÄÏùÑ Ìï¥Ï§ò. ÎÖ∏Ìä∏Ïóê ÎÇ¥Ïö©Ïù¥ Ï†ïÌôïÌïòÍ≤å ÎÇòÏôÄÏûàÏßÄ ÏïäÏúºÎ©¥ ÎÑàÏùò ÏßÄÏãù ÏÑ†ÏóêÏÑú Ïûò ÏñòÍ∏∞Ìï¥Ï§ò. ÎãµÎ≥ÄÏùÄ ÎÖºÎ¶¨Ï†ÅÏúºÎ°ú Ïù¥Ìï¥ ÌïòÍ∏∞ ÏâΩÍ≤å ÏòàÎ•º Îì§Ïñ¥ÏÑú ÏÑ§Î™ÖÌï¥Ï§ò. Ïù¥Î™®Ìã∞ÏΩòÏùÑ Ï†ÅÏ†àÌûà Ï∂îÍ∞ÄÌïòÏó¨ Ïù¥Ìï¥Î•º ÎèÑÏôÄÏ§ò! ÎãµÎ≥ÄÏùÑ ÏûòÌïòÎ©¥ 200Îã¨Îü¨ ÌåÅÏùÑ Ï§ÑÍ≤å"
        ),
        HumanMessage(
            content=f"ÏßàÎ¨∏:{query_text}\n\nÍ∞ïÏùòÎÖ∏Ìä∏:\n{pdf_text}\n\nYouTube Í∞ïÏùò ÎÇ¥Ïö©:\n{youtube_text}"
        ),
        *examples
    ]

    response = llm(rag_prompt)
    
    return response.content


def generate_summarize(raw_text, callback):
    # generator 
    llm = ChatOpenAI(model_name="gpt-4o", temperature=0.2, streaming=True, callbacks=[callback])
    
    # prompt formatting
    rag_prompt = [
        SystemMessage(
            content="Îã§Ïùå ÎÇòÏò¨ Î¨∏ÏÑúÎ•º 'Notion style'Î°ú ÏöîÏïΩÌï¥Ï§ò. Ï§ëÏöîÌïú ÎÇ¥Ïö©Îßå."
        ),
        HumanMessage(
            content=raw_text
        ),
    ]
    
    response = llm(rag_prompt)
    return response.content


# page title
st.set_page_config(page_title='üéì CS182 Í∞ïÏùòÎ¥á ü§ñ')
st.title('üéì CS182 Í∞ïÏùòÎ¥á ü§ñ')

# enter token
import os
api_key = st.sidebar.text_input("Enter your OpenAI API Key", type="password")
save_button = st.sidebar.button("Save Key")
if save_button and len(api_key)>10:
    os.environ["OPENAI_API_KEY"] = api_key
    st.sidebar.success("API Key saved successfully!")

# Ï¥àÍ∏∞Ìôî ÏΩîÎìú Ï∂îÍ∞Ä
if 'vectorstores' not in st.session_state:
    st.session_state['vectorstores'] = {}

if 'youtube_vectorstores' not in st.session_state:
    st.session_state['youtube_vectorstores'] = {}

if 'youtube_scripts' not in st.session_state:
    st.session_state['youtube_scripts'] = {}

if 'raw_texts' not in st.session_state:
    st.session_state['raw_texts'] = {}

# file upload
uploaded_file = st.file_uploader('Upload lecture PDFs', type=['pdf'], accept_multiple_files=True)

# file upload logic
if uploaded_file:
    vectorstore, raw_text = process_uploaded_file(uploaded_file)
    if vectorstore:
        st.session_state['vectorstore'] = vectorstore
        st.session_state['raw_text'] = raw_text

lecture_titles = [
    "Lecture 1: Introduction.",
    "Lecture 2: ML Basics 1.",
    "Lecture 3: ML Basics 2.",
    "Lecture 4: Optimization.",
    "Lecture 5: Backpropagation.",
    "Lecture 6: Convolutional Nets.",
    "Lecture 7: Getting Neural Nets to Train.",
    "Lecture 8: Computer Vision.",
    "Lecture 9: Generating Images from CNNs.",
    "Lecture 10: Recurrent Neural Networks.",
    "Lecture 11: Sequence To Sequence Models."
]
lecture_urls = {
    "Lecture 1": [
        "https://youtu.be/rSY1pVGdZ4I?si=HJ0w04z57oSg3l2T",
        "https://youtu.be/FHsGHxQYxvc?si=swR3M09Xdjk2SJWP",
        "https://youtu.be/s2B0c_o_rbw?si=eZckP8Pyg4fM_Fks"
    ],
    "Lecture 2": [
        "https://youtu.be/aUNnGCxvAg0?si=3J7nzJWWkXpRCBLA",
        "https://youtu.be/oLc822BT-K4?si=SiefY6V5gHgrxsSg",
        "https://youtu.be/zY2QgvPfSm8?si=1f6G4Lplz1KU3CSe",
        "https://youtu.be/voJ4qSH-uqw?si=78149mesZb3s7Q_w"
    ],
    "Lecture 3": [
        "https://youtu.be/PBYWWM9We-0?si=h4r-KtBupFJg3keO",
        "https://youtu.be/U_cpdaJ-adk?si=NtW8t0ePyBVb21Jj",
        "https://youtu.be/-BKfF-odbSQ?si=Xhc9iuIoNLEymFon"
    ],
    "Lecture 4": [
        "https://youtu.be/RdoZWcXmXhk?si=N5LuULe3QIgSMRIm",
        "https://youtu.be/fg3GyrfcclY?si=eWTtemPPOTP2rZrj",
        "https://youtu.be/CO3-sFmADfI?si=lQA0eQOcm4VuRVKd"
    ],
    "Lecture 5": [
        "https://youtu.be/lKRatcD9hEg?si=r5jvTTkdEkJfLroF",
        "https://youtu.be/hpS8oIEQzcs?si=49QCQNknyEEwnqFE",
        "https://youtu.be/JXX5Ea0TXTM?si=J4ZnAEfw0bWxzQDN"
    ],
    "Lecture 6": [
        "https://youtu.be/jNW1Hi7Yi4c?si=M9WySH60Fu_ACYSQ",
        "https://youtu.be/xAcAWaeUxYs?si=U00725uJOmw3Kc68",
        "https://youtu.be/HlJ8rpwKH5c?si=wZxQ54C3rqWt3IOV"
    ],
    "Lecture 7": [
        "https://youtu.be/0dNAhN4ypFc?si=fhPcIy_ZOLBZaYsL",
        "https://youtu.be/k5uLipr49zQ?si=3UJobqmLZ2dvdsfR",
        "https://youtu.be/Nx48Idc0_68?si=2YCsgZdxRbaKqTCi"
    ],
    "Lecture 8": [
        "https://youtu.be/MgabSQ93IE8?si=jnehT9qW1AAnKRMS",
        "https://youtu.be/XHrSobup-vU?si=NKbwf4jeyeXljS68",
        "https://youtu.be/gAH5dH2uTc0?si=BsZS33KsXDPi7996",
        "https://youtu.be/LACVGqw29J0?si=6zCKYMdH7z5FEuQl"
    ],
    "Lecture 9": [
        "https://youtu.be/VKPkM6jt_P0?si=yskt4ZNb7ZOpkvUy",
        "https://youtu.be/AsGaxH7vizk?si=wK3z9cjugbYRNd3I",
        "https://youtu.be/vyfq3SgXQyU?si=NALHovpFSjvxXQYg"
    ],
    "Lecture 10": [
        "https://youtu.be/PyZvbaC5oQY?si=rBY8s8ZYVXFqry4G",
        "https://youtu.be/BOyQQbQzKG4?si=xDzo7xyhQ7_PuR-x",
        "https://youtu.be/EFbKmZdB61g?si=zOyt0b5u1mnJ0DcO"
    ],
    "Lecture 11": [
        "https://youtu.be/36RjPbbcA28?si=KT2pgr0-cEHiMuNm",
        "https://youtu.be/VX5_uKOUliE?si=5hpggIGAOg8n6_fK",
        "https://youtu.be/49wn_m7JE-c?si=4ip0JWDjyvCGmiRE"
    ],
}

st.sidebar.header("Í∞ïÏùò Î™©Î°ù")
selected_lecture = st.sidebar.selectbox("Í∞ïÏùòÎ•º ÏÑ†ÌÉùÌïòÏÑ∏Ïöî", lecture_titles)

if selected_lecture:
    lecture_key = selected_lecture.split(":")[0]
    #if "youtube_scripts" not in st.session_state:
    #    st.session_state["youtube_scripts"] = {}
    
    if lecture_key not in st.session_state["youtube_scripts"]:
        st.session_state["youtube_scripts"][lecture_key] = load_youtube_scripts(lecture_urls[lecture_key])

    #if "youtube_vectorstores" not in st.session_state:
    #    st.session_state["youtube_vectorstores"] = {}
    
    if lecture_key not in st.session_state["youtube_vectorstores"]:
        scripts = st.session_state["youtube_scripts"][lecture_key]
        all_splits = []
        text_splitter = RecursiveCharacterTextSplitter(
            chunk_size=500,
            chunk_overlap=50
        )
        for script in scripts:
            splits = text_splitter.create_documents([script])
            all_splits.extend(splits)
        try:
            embeddings = OpenAIEmbeddings().embed_documents([doc.page_content for doc in all_splits])
            if not embeddings:
                st.error("Failed to generate embeddings. Check your API key and internet connection.")
            vectorstore = FAISS.from_documents(documents=all_splits, embedding=OpenAIEmbeddings())
            st.session_state["youtube_vectorstores"][lecture_key] = vectorstore
        except Exception as e:
            st.error(f"Error creating FAISS vectorstore for YouTube scripts of {lecture_key}: {e}")

# chatbot greatings
if "messages" not in st.session_state:
    st.session_state["messages"] = [
        ChatMessage(
            role="assistant", content="ÏïàÎÖïÌïòÏÑ∏Ïöî‚úã! Ï†ÄÎäî CS182 Í∞ïÏùòÏóê ÎåÄÌïú Ïù¥Ìï¥Î•º ÎèÑÏôÄÏ£ºÎäî Ï±óÎ¥áÏûÖÎãàÎã§. Ïñ¥Îñ§Í≤å Í∂ÅÍ∏àÌïòÏã†Í∞ÄÏöî?"
        )
    ]

# conversation history print 
for msg in st.session_state.messages:
    st.chat_message(msg.role).write(msg.content)
    
# message interaction
if prompt := st.chat_input(f"'{selected_lecture}'Ïóê ÎåÄÌïú ÏßàÎ¨∏ÏùÑ ÏûÖÎ†•Ìï¥Î≥¥ÏÑ∏Ïöî!"):
    st.session_state.messages.append(ChatMessage(role="user", content=prompt))
    st.chat_message("user").write(prompt)

    stream_handler = StreamHandler(st.empty())
    if "ÏöîÏïΩ" in prompt.lower():
        if lecture_key in st.session_state['raw_texts']:
            response = generate_summarize(st.session_state['raw_texts'][lecture_key], stream_handler)
        else:
            response = "ÏÑ†ÌÉùÎêú Í∞ïÏùòÏóê ÎåÄÌïú ÏõêÎ≥∏ ÌÖçÏä§Ìä∏Í∞Ä ÏóÜÏäµÎãàÎã§."
    else:
        if lecture_key in st.session_state['vectorstores'] and lecture_key in st.session_state['youtube_vectorstores']:
            response = generate_response(
                prompt,
                st.session_state['vectorstores'][lecture_key],
                st.session_state['youtube_vectorstores'][lecture_key],
                stream_handler
            )
        else:
            response = "ÏÑ†ÌÉùÎêú Í∞ïÏùòÏóê ÎåÄÌïú Îç∞Ïù¥ÌÑ∞Í∞Ä ÏóÜÏäµÎãàÎã§."

    st.session_state["messages"].append(ChatMessage(role="assistant", content=response))
    st.chat_message("assistant").write(response)
